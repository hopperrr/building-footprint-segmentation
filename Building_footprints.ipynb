{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building_footprints.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN3D0VQ092+y1ItBN+HLFjb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hopperrr/building-footprint-segmentation/blob/main/Building_footprints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: https://github.com/santhi-2020/building-footprint-segmentation/blob/main/temp.py"
      ],
      "metadata": {
        "id": "29HJV0czorho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ch3V2CBopoM"
      },
      "outputs": [],
      "source": [
        "!pip install building-footprint-segmentation\n",
        "!pip install geospatial\n",
        "#!pip install rasterio\n",
        "#!pip install geopandas\n",
        "#!pip install leafmap\n",
        "#!pip install xarray_leaflet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create goog.xml file for pulling satellite image\n",
        "%%writefile goog.xml\n",
        "<GDAL_WMS>\n",
        "\n",
        "<!-- Data is subject to term of use detailed at http://code.google.com/intl/nl/apis/maps/terms.html and\n",
        "     http://www.google.com/intl/en_ALL/help/terms_maps.html -->\n",
        "\n",
        "    <Service name=\"TMS\">\n",
        "        <!-- <ServerUrl>http://mt.google.com/vt/lyrs=m&amp;x=${x}&amp;y=${y}&amp;z=${z}</ServerUrl> --> <!-- Map -->\n",
        "        <ServerUrl>http://mt.google.com/vt/lyrs=s&amp;x=${x}&amp;y=${y}&amp;z=${z}</ServerUrl> <!-- Satellite -->\n",
        "        <!-- <ServerUrl>http://mt.google.com/vt/lyrs=y&amp;x=${x}&amp;y=${y}&amp;z=${z}</ServerUrl> --> <!-- Hybrid -->\n",
        "        <!-- <ServerUrl>http://mt.google.com/vt/lyrs=t&amp;x=${x}&amp;y=${y}&amp;z=${z}</ServerUrl> --> <!-- Terrain -->\n",
        "        <!-- <ServerUrl>http://mt.google.com/vt/lyrs=p&amp;x=${x}&amp;y=${y}&amp;z=${z}</ServerUrl> --> <!-- Terrain, Streets and Water  -->\n",
        "    </Service>\n",
        "    <DataWindow>\n",
        "        <UpperLeftX>-20037508.34</UpperLeftX>\n",
        "        <UpperLeftY>20037508.34</UpperLeftY>\n",
        "        <LowerRightX>20037508.34</LowerRightX>\n",
        "        <LowerRightY>-20037508.34</LowerRightY>\n",
        "        <TileLevel>20</TileLevel>\n",
        "        <TileCountX>1</TileCountX>\n",
        "        <TileCountY>1</TileCountY>\n",
        "        <YOrigin>top</YOrigin>\n",
        "    </DataWindow>\n",
        "    <Projection>EPSG:3857</Projection>\n",
        "    <BlockSizeX>256</BlockSizeX>\n",
        "    <BlockSizeY>256</BlockSizeY>\n",
        "    <BandsCount>3</BandsCount>\n",
        "    <MaxConnections>5</MaxConnections>\n",
        "    <Cache />\n",
        "</GDAL_WMS>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N5yyMlNAqIH",
        "outputId": "28ddbf9b-e1fb-4282-e157-aa164613793f",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing goog.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from osgeo import gdal\n",
        "#Sample area: 1599243.53,5064967.27\n",
        "#1599837.10,5065633.91\n",
        "#LW: -13146232.8,3998522.4\n",
        "\n",
        "#Paste the values into the coords array below\n",
        "coords = [1599243.53,5064967.27]\n",
        "ulx = coords[0]\n",
        "uly = coords[1]\n",
        "llx = ulx + 1000\n",
        "lly = uly - 1000\n",
        "ds = gdal.Open('goog.xml')\n",
        "ds = gdal.Translate('/content/satellite.png', ds, format = 'PNG', projWin = [ulx, uly, llx, lly], width = 3200, height = 3200)\n",
        "ds = None"
      ],
      "metadata": {
        "id": "QQZPuuuhFinB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from building_footprint_segmentation.seg.binary.models import ReFineNet\n",
        "from building_footprint_segmentation.helpers.normalizer import min_max_image_net\n",
        "from building_footprint_segmentation.utils.py_network import (\n",
        "    to_input_image_tensor,\n",
        "    add_extra_dimension,\n",
        "    convert_tensor_to_numpy,\n",
        "    load_parallel_model\n",
        ")\n",
        "from building_footprint_segmentation.utils.operations import handle_image_size\n",
        "from torch.utils import model_zoo\n",
        "#Size needs to be divisible by 32 (I think). CUDA has problems with memory when image is 4000 x 4000 +\n",
        "MAX_SIZE = 3200\n",
        "#MAX_SIZE = 256\n",
        "MODEL_URL = \"https://github.com/fuzailpalnak/building-footprint-segmentation/releases/download/alpha/refine.zip\"\n",
        "blank_image = np.zeros((MAX_SIZE,MAX_SIZE,3), np.uint8)\n",
        "\n",
        "def get_model():\n",
        "    refine_net = ReFineNet()\n",
        "    state_dict = model_zoo.load_url(MODEL_URL, progress=True, map_location=\"cpu\")\n",
        "    refine_net.load_state_dict(state_dict)\n",
        "    return refine_net\n",
        "\n",
        "\n",
        "def extract(original_image, model):\n",
        "\n",
        "    original_height, original_width = original_image.shape[:2]\n",
        "\n",
        "    if (original_height, original_width) != (MAX_SIZE, MAX_SIZE):\n",
        "        original_image = handle_image_size(original_image, (MAX_SIZE, MAX_SIZE))\n",
        "\n",
        "    # Apply Normalization\n",
        "    normalized_image = min_max_image_net(img=original_image)\n",
        "\n",
        "    tensor_image = add_extra_dimension(to_input_image_tensor(normalized_image))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Perform prediction\n",
        "        prediction = model(tensor_image)\n",
        "        prediction = prediction.sigmoid()\n",
        "    \n",
        "    prediction_binary = convert_tensor_to_numpy(prediction[0]).reshape(\n",
        "        (MAX_SIZE, MAX_SIZE)\n",
        "    \n",
        "    )\n",
        "\n",
        "\n",
        "    prediction_3_channels = cv2.cvtColor(prediction_binary, cv2.COLOR_GRAY2RGB)\n",
        "    \n",
        "    print (prediction_3_channels[0])\n",
        "        \n",
        "    dst = cv2.addWeighted(\n",
        "        blank_image,\n",
        "        1,\n",
        "        #(prediction_3_channels * (255,69,0)).astype(np.uint8),\n",
        "        (prediction_3_channels * (255,255,255)).astype(np.uint8),\n",
        "        #0.4,\n",
        "        #0\n",
        "        1.0,\n",
        "        0,\n",
        "    )\n",
        "   # cv2.imshow (\"test\", prediction_3_channels)\n",
        "   # cv2.waitKey(0)\n",
        "    \n",
        "    cv2.imwrite (\"/content/predict.png\", dst)\n",
        "\n",
        "    return prediction_binary, prediction_3_channels, dst\n",
        "\n",
        "\n",
        "def run(image_path):\n",
        "    original_image = cv2.imread(image_path)\n",
        "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    model = get_model()\n",
        "    # PARALLELIZE the model if gpu available\n",
        "    model = load_parallel_model(model)\n",
        "    \n",
        "    prediction_binary, prediction_3_channels, dst = extract(original_image, model)\n",
        "    return prediction_3_channels\n",
        "    \n",
        "   \n",
        "dst = run ('/content/satellite.png')\n",
        "!cp /content/satellite.png.aux.xml /content/predict.png.aux.xml"
      ],
      "metadata": {
        "id": "d5bFgz25pEJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import geopandas\n",
        "import fiona\n",
        "from google.colab import files\n",
        "img = Image.open('/content/predict.png')\n",
        "rgba = img.convert(\"RGBA\")\n",
        "datas = rgba.getdata()\n",
        "  \n",
        "newData = []\n",
        "for item in datas:\n",
        "    if item[0] == 255 and item[1] == 255 and item[2] == 255:  # finding black colour by its RGB value\n",
        "        # storing a transparent value when we find a black colour\n",
        "        newData.append((255, 255, 255, 0))\n",
        "    else:\n",
        "        newData.append(item)  # other colours remain unchanged\n",
        "  \n",
        "rgba.putdata(newData)\n",
        "\n",
        "rgba.save(\"/content/rectified_transparent.png\", \"PNG\")\n",
        "!cp /content/satellite.png.aux.xml rectified_transparent.png.aux.xml\n",
        "\n",
        "!gdal_polygonize.py \"/content/rectified_transparent.png\" -mask /content/rectified_transparent.png -b 1 -f \"GPKG\" OUTPUT.gpkg OUTPUT DN\n",
        "unsimplified_gdf = geopandas.read_file(\"/content/OUTPUT.gpkg\", layer='output')\n",
        "gdf_simplified = unsimplified_gdf\n",
        "gdf_simplified['geometry'] = gdf_simplified['geometry'].simplify(0.5).buffer(0)\n",
        "gdf254 = gdf_simplified[(gdf_simplified['DN'] > 253)]\n",
        "gdf254_4326  = gdf254.to_crs({'init': 'epsg:4326'})"
      ],
      "metadata": {
        "id": "9lj8IxXeZ-0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import leafmap\n",
        "m = leafmap.Map(google_map=\"HYBRID\", center=[14.3, 41.4], zoom=6)\n",
        "#datasets need to be in EPSG:4326???\n",
        "m.add_gdf(gdf254_4326, layer_name=\"buildings\")\n",
        "m"
      ],
      "metadata": {
        "id": "27Uk02LnaGim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bringing in code from another project to see if the polygons can be cleaned up.**"
      ],
      "metadata": {
        "id": "7DLHhSzrND1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hopperrr/RS-building-regularization.git\n",
        "%cd RS-building-regularization/"
      ],
      "metadata": {
        "id": "7ge8mGRqNA-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "  \n",
        "img = Image.open('/content/predict.png')\n",
        "rgba = img.convert(\"RGBA\")\n",
        "datas = rgba.getdata()\n",
        "  \n",
        "newData = []\n",
        "for item in datas:\n",
        "    if item[0] >= 0 and item[1] >= 0 and item[2] >= 0:  # finding black colour by its RGB value\n",
        "        # storing a transparent value when we find a black colour\n",
        "        newData.append((255, 255, 255, 0))\n",
        "    else:\n",
        "        newData.append(item)  # other colours remain unchanged\n",
        "  \n",
        "rgba.putdata(newData)\n",
        "rgba.save(\"/content/transparent_image.png\", \"PNG\")"
      ],
      "metadata": {
        "id": "R6-4Lh0zydbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from rdp_alg import rdp\n",
        "from cal_dist_ang import cal_ang, cal_dist, azimuthAngle\n",
        "from rotate_ang import Nrotation_angle_get_coor_coordinates, Srotation_angle_get_coor_coordinates\n",
        "from line_intersection import line, intersection, par_line_dist, point_in_line\n",
        "\n",
        "def boundary_regularization(img, epsilon=6):\n",
        "    h, w = img.shape[0:2]\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = np.squeeze(contours[0])\n",
        "\n",
        "\n",
        "\n",
        "    contours = rdp(contours, epsilon=epsilon)\n",
        "\n",
        "    contours[:, 1] = h - contours[:, 1]\n",
        "\n",
        "\n",
        "    dists = []\n",
        "    azis = []\n",
        "    azis_index = []\n",
        "\n",
        "\n",
        "    for i in range(contours.shape[0]):\n",
        "        cur_index = i\n",
        "        next_index = i+1 if i < contours.shape[0]-1 else 0\n",
        "        prev_index = i-1\n",
        "        cur_point = contours[cur_index]\n",
        "        nest_point = contours[next_index]\n",
        "        prev_point = contours[prev_index]\n",
        "\n",
        "        dist = cal_dist(cur_point, nest_point)\n",
        "        azi = azimuthAngle(cur_point, nest_point)\n",
        "\n",
        "        dists.append(dist)\n",
        "        azis.append(azi)\n",
        "        azis_index.append([cur_index, next_index])\n",
        "\n",
        "\n",
        "\n",
        "    longest_edge_idex = np.argmax(dists)\n",
        "    main_direction = azis[longest_edge_idex]\n",
        "\n",
        "\n",
        "    correct_points = []\n",
        "    para_vetr_idxs = [] \n",
        "    for i, (azi, (point_0_index, point_1_index)) in enumerate(zip(azis, azis_index)):\n",
        "\n",
        "        if i == longest_edge_idex:\n",
        "            correct_points.append([contours[point_0_index], contours[point_1_index]])\n",
        "            para_vetr_idxs.append(0)\n",
        "        else:\n",
        "            rotate_ang = main_direction - azi\n",
        "\n",
        "            if np.abs(rotate_ang) < 180/4:\n",
        "                rotate_ang = rotate_ang\n",
        "                para_vetr_idxs.append(0)\n",
        "            elif np.abs(rotate_ang) >= 90-180/4:\n",
        "                rotate_ang = rotate_ang + 90\n",
        "                para_vetr_idxs.append(1)\n",
        "\n",
        "\n",
        "            point_0 = contours[point_0_index]\n",
        "            point_1 = contours[point_1_index]\n",
        "            point_middle = (point_0 + point_1) / 2\n",
        "\n",
        "            if rotate_ang > 0:\n",
        "                rotate_point_0 = Srotation_angle_get_coor_coordinates(point_0, point_middle, np.abs(rotate_ang))\n",
        "                rotate_point_1 = Srotation_angle_get_coor_coordinates(point_1, point_middle, np.abs(rotate_ang))\n",
        "            elif rotate_ang < 0:\n",
        "                rotate_point_0 = Nrotation_angle_get_coor_coordinates(point_0, point_middle, np.abs(rotate_ang))\n",
        "                rotate_point_1 = Nrotation_angle_get_coor_coordinates(point_1, point_middle, np.abs(rotate_ang))\n",
        "            else:\n",
        "                rotate_point_0 = point_0\n",
        "                rotate_point_1 = point_1\n",
        "            correct_points.append([rotate_point_0, rotate_point_1])\n",
        "\n",
        "    correct_points = np.array(correct_points)\n",
        "\n",
        "\n",
        "    final_points = []\n",
        "    final_points.append(correct_points[0][0])\n",
        "    for i in range(correct_points.shape[0]-1):\n",
        "        cur_index = i\n",
        "        next_index = i + 1 if i < correct_points.shape[0] - 1 else 0\n",
        "\n",
        "        cur_edge_point_0 = correct_points[cur_index][0]\n",
        "        cur_edge_point_1 = correct_points[cur_index][1]\n",
        "        next_edge_point_0 = correct_points[next_index][0]\n",
        "        next_edge_point_1 = correct_points[next_index][1]\n",
        "\n",
        "        cur_para_vetr_idx = para_vetr_idxs[cur_index]\n",
        "        next_para_vetr_idx = para_vetr_idxs[next_index]\n",
        "\n",
        "        if cur_para_vetr_idx != next_para_vetr_idx:\n",
        "            L1 = line(cur_edge_point_0, cur_edge_point_1)\n",
        "            L2 = line(next_edge_point_0, next_edge_point_1)\n",
        "\n",
        "            point_intersection = intersection(L1, L2)\n",
        "            final_points.append(point_intersection)\n",
        "\n",
        "        elif cur_para_vetr_idx == next_para_vetr_idx:\n",
        "            L1 = line(cur_edge_point_0, cur_edge_point_1)\n",
        "            L2 = line(next_edge_point_0, next_edge_point_1)\n",
        "            marg = par_line_dist(L1, L2)\n",
        "\n",
        "            if marg < 3:\n",
        "\n",
        "                point_move = point_in_line(next_edge_point_0[0], next_edge_point_0[1], cur_edge_point_0[0], cur_edge_point_0[1], cur_edge_point_1[0], cur_edge_point_1[1])\n",
        "                final_points.append(point_move)\n",
        "\n",
        "                correct_points[next_index][0] = point_move\n",
        "                correct_points[next_index][1] = point_in_line(next_edge_point_1[0], next_edge_point_1[1], cur_edge_point_0[0], cur_edge_point_0[1], cur_edge_point_1[0], cur_edge_point_1[1])\n",
        "\n",
        "\n",
        "            else:\n",
        "\n",
        "                add_mid_point = (cur_edge_point_1 + next_edge_point_0) / 2\n",
        "                add_point_1 = point_in_line(add_mid_point[0], add_mid_point[1], cur_edge_point_0[0], cur_edge_point_0[1], cur_edge_point_1[0], cur_edge_point_1[1])\n",
        "                add_point_2 = point_in_line(add_mid_point[0], add_mid_point[1], next_edge_point_0[0], next_edge_point_0[1], next_edge_point_1[0], next_edge_point_1[1])\n",
        "                final_points.append(add_point_1)\n",
        "                final_points.append(add_point_2)\n",
        "\n",
        "\n",
        "    final_points.append(final_points[0])\n",
        "    final_points = np.array(final_points)\n",
        "\n",
        "    final_points[:, 1] = h - final_points[:, 1]\n",
        "    return final_points\n",
        "\n",
        "\n",
        "#ori_img1 = cv2.imread('./input_data/ori.jpg')\n",
        "trans_img = cv2.imread('/content/transparent_image.png')\n",
        "ori_img1 = cv2.imread('/content/predict.png')\n",
        "ori_img = cv2.medianBlur(ori_img1, 5)\n",
        "ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2GRAY)\n",
        "ret, ori_img = cv2.threshold(ori_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(ori_img, connectivity=8)\n",
        "print(num_labels)\n",
        "\n",
        "\n",
        "for i in range(1, num_labels):\n",
        "    img = np.zeros_like(labels)\n",
        "    index = np.where(labels==i)\n",
        "    img[index] = 255\n",
        "    img = np.array(img, dtype=np.uint8)\n",
        "\n",
        "    regularization_contour = boundary_regularization(img).astype(np.int32)\n",
        "\n",
        "    #cv2.polylines(img=ori_img1, pts=[regularization_contour], isClosed=True, color=(255, 0, 0), thickness=5)\n",
        "    #cv2.polylines(img=trans_img, pts=[regularization_contour], isClosed=True, color=(255, 0, 0), thickness=1)\n",
        "    cv2.fillPoly(img=trans_img, pts=[regularization_contour], color =(255,0,0))\n",
        "\n",
        "    single_out = np.zeros_like(ori_img1)\n",
        "    #cv2.polylines(img=single_out, pts=[regularization_contour], isClosed=True, color=(255, 0, 0), thickness=5)\n",
        "    cv2.fillPoly(img=single_out, pts = [regularization_contour], color =(255,0,0))\n",
        "    cv2.imwrite('/content/RS-building-regularization/output_data/single_out_{}.png'.format(i), single_out)\n",
        "\n",
        "cv2.imwrite('all_out.png', ori_img1)\n",
        "cv2.imwrite('rectified.png', trans_img)\n",
        "!cp /content/satellite.png.aux.xml rectified.png.aux.xml"
      ],
      "metadata": {
        "id": "Yq6glx-zb-iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import geopandas\n",
        "import fiona\n",
        "from google.colab import files\n",
        "#img = Image.open('/content/RS-building-regularization/rectified.png')\n",
        "img = Image.open('/content/predict.png')\n",
        "rgba = img.convert(\"RGBA\")\n",
        "datas = rgba.getdata()\n",
        "  \n",
        "newData = []\n",
        "for item in datas:\n",
        "    if item[0] == 255 and item[1] == 255 and item[2] == 255:  # finding black colour by its RGB value\n",
        "        # storing a transparent value when we find a black colour\n",
        "        newData.append((255, 255, 255, 0))\n",
        "    else:\n",
        "        newData.append(item)  # other colours remain unchanged\n",
        "  \n",
        "rgba.putdata(newData)\n",
        "rgba.save(\"/content/RS-building-regularization/rectified_transparent.png\", \"PNG\")\n",
        "!cp /content/satellite.png.aux.xml rectified_transparent.png.aux.xml\n",
        "\n",
        "!gdal_polygonize.py \"/content/RS-building-regularization/rectified_transparent.png\" -mask /content/RS-building-regularization/rectified.png -b 1 -f \"GPKG\" OUTPUT.gpkg OUTPUT DN\n",
        "unsimplified_gdf = geopandas.read_file(\"/content/RS-building-regularization/OUTPUT.gpkg\", layer='output')\n",
        "gdf_simplified = unsimplified_gdf\n",
        "gdf_simplified['geometry'] = gdf_simplified['geometry'].simplify(0.5).buffer(0)\n",
        "gdf_simplified.to_file(\"simplified.gpkg\", layer='simple', driver=\"GPKG\")\n",
        "#!ogr2ogr -t_srs EPSG:4326 -f GPKG out4326.gpkg simplified.gpkg\n",
        "#!zip out.zip /content/RS-building-regularization/rectified_transparent.png  simplified.gpkg /content/RS-building-regularization/rectified_transparent.png.aux.xml\n",
        "#!zip out.zip /content/rectified_transparent.png  out4326.gpkg /content/rectified_transparent.png.aux.xml\n",
        "#files.download('out.zip')"
      ],
      "metadata": {
        "id": "6k3LDEBEGZb2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}