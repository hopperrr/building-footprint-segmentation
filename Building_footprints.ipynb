{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building_footprints.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6l+lF15DzfdOV8llJtAwa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hopperrr/building-footprint-segmentation/blob/main/Building_footprints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: https://github.com/santhi-2020/building-footprint-segmentation/blob/main/temp.py"
      ],
      "metadata": {
        "id": "29HJV0czorho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ch3V2CBopoM"
      },
      "outputs": [],
      "source": [
        "!pip install building-footprint-segmentation\n",
        "!pip install rasterio\n",
        "!pip install geopandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create goog.xml file for pulling satellite image\n",
        "%%writefile goog.xml\n",
        "<GDAL_WMS>\n",
        "\n",
        "<!-- Data is subject to term of use detailed at http://code.google.com/intl/nl/apis/maps/terms.html and\n",
        "     http://www.google.com/intl/en_ALL/help/terms_maps.html -->\n",
        "\n",
        "    <Service name=\"TMS\">\n",
        "        <!-- <ServerUrl>http://mt.google.com/vt/lyrs=m&amp;x=${x}&amp;y=${y}&amp;z=${z}</ServerUrl> --> <!-- Map -->\n",
        "        <ServerUrl>http://mt.google.com/vt/lyrs=s&amp;x=${x}&amp;y=${y}&amp;z=${z}</ServerUrl> <!-- Satellite -->\n",
        "        <!-- <ServerUrl>http://mt.google.com/vt/lyrs=y&amp;x=${x}&amp;y=${y}&amp;z=${z}</ServerUrl> --> <!-- Hybrid -->\n",
        "        <!-- <ServerUrl>http://mt.google.com/vt/lyrs=t&amp;x=${x}&amp;y=${y}&amp;z=${z}</ServerUrl> --> <!-- Terrain -->\n",
        "        <!-- <ServerUrl>http://mt.google.com/vt/lyrs=p&amp;x=${x}&amp;y=${y}&amp;z=${z}</ServerUrl> --> <!-- Terrain, Streets and Water  -->\n",
        "    </Service>\n",
        "    <DataWindow>\n",
        "        <UpperLeftX>-20037508.34</UpperLeftX>\n",
        "        <UpperLeftY>20037508.34</UpperLeftY>\n",
        "        <LowerRightX>20037508.34</LowerRightX>\n",
        "        <LowerRightY>-20037508.34</LowerRightY>\n",
        "        <TileLevel>20</TileLevel>\n",
        "        <TileCountX>1</TileCountX>\n",
        "        <TileCountY>1</TileCountY>\n",
        "        <YOrigin>top</YOrigin>\n",
        "    </DataWindow>\n",
        "    <Projection>EPSG:3857</Projection>\n",
        "    <BlockSizeX>256</BlockSizeX>\n",
        "    <BlockSizeY>256</BlockSizeY>\n",
        "    <BandsCount>3</BandsCount>\n",
        "    <MaxConnections>5</MaxConnections>\n",
        "    <Cache />\n",
        "</GDAL_WMS>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N5yyMlNAqIH",
        "outputId": "5cfc00db-3020-473f-ea01-a9f609c4eda1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing goog.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from osgeo import gdal\n",
        "#Piedimonte Matese: 1599243.53,5064967.27\n",
        "#1599837.10,5065633.91\n",
        "#LW: -13146232.8,3998522.4\n",
        "\n",
        "#Paste the values into the coords array below\n",
        "coords = [-13133532.68,3990585.55]\n",
        "ulx = coords[0]\n",
        "uly = coords[1]\n",
        "llx = ulx + 1000\n",
        "lly = uly - 1000\n",
        "ds = gdal.Open('goog.xml')\n",
        "ds = gdal.Translate('/content/satellite.png', ds, format = 'PNG', projWin = [ulx, uly, llx, lly], width = 3200, height = 3200)\n",
        "ds = None"
      ],
      "metadata": {
        "id": "QQZPuuuhFinB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from building_footprint_segmentation.seg.binary.models import ReFineNet\n",
        "from building_footprint_segmentation.helpers.normalizer import min_max_image_net\n",
        "from building_footprint_segmentation.utils.py_network import (\n",
        "    to_input_image_tensor,\n",
        "    add_extra_dimension,\n",
        "    convert_tensor_to_numpy,\n",
        "    load_parallel_model\n",
        ")\n",
        "from building_footprint_segmentation.utils.operations import handle_image_size\n",
        "from torch.utils import model_zoo\n",
        "#Size needs to be divisible by 32 (I think). CUDA has problems with memory when image is 4000 x 4000 +\n",
        "MAX_SIZE = 3200\n",
        "#MAX_SIZE = 256\n",
        "MODEL_URL = \"https://github.com/fuzailpalnak/building-footprint-segmentation/releases/download/alpha/refine.zip\"\n",
        "blank_image = np.zeros((MAX_SIZE,MAX_SIZE,3), np.uint8)\n",
        "\n",
        "def get_model():\n",
        "    refine_net = ReFineNet()\n",
        "    state_dict = model_zoo.load_url(MODEL_URL, progress=True, map_location=\"cpu\")\n",
        "    refine_net.load_state_dict(state_dict)\n",
        "    return refine_net\n",
        "\n",
        "\n",
        "def extract(original_image, model):\n",
        "\n",
        "    original_height, original_width = original_image.shape[:2]\n",
        "\n",
        "    if (original_height, original_width) != (MAX_SIZE, MAX_SIZE):\n",
        "        original_image = handle_image_size(original_image, (MAX_SIZE, MAX_SIZE))\n",
        "\n",
        "    # Apply Normalization\n",
        "    normalized_image = min_max_image_net(img=original_image)\n",
        "\n",
        "    tensor_image = add_extra_dimension(to_input_image_tensor(normalized_image))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Perform prediction\n",
        "        prediction = model(tensor_image)\n",
        "        prediction = prediction.sigmoid()\n",
        "    \n",
        "    prediction_binary = convert_tensor_to_numpy(prediction[0]).reshape(\n",
        "        (MAX_SIZE, MAX_SIZE)\n",
        "    \n",
        "    )\n",
        "\n",
        "\n",
        "    prediction_3_channels = cv2.cvtColor(prediction_binary, cv2.COLOR_GRAY2RGB)\n",
        "    \n",
        "    print (prediction_3_channels[0])\n",
        "        \n",
        "    dst = cv2.addWeighted(\n",
        "        blank_image,\n",
        "        1,\n",
        "        #(prediction_3_channels * (255,69,0)).astype(np.uint8),\n",
        "        (prediction_3_channels * (255,255,255)).astype(np.uint8),\n",
        "        #0.4,\n",
        "        #0\n",
        "        1.0,\n",
        "        0,\n",
        "    )\n",
        "   # cv2.imshow (\"test\", prediction_3_channels)\n",
        "   # cv2.waitKey(0)\n",
        "    \n",
        "    cv2.imwrite (\"/content/predict.png\", dst)\n",
        "\n",
        "    return prediction_binary, prediction_3_channels, dst\n",
        "\n",
        "\n",
        "def run(image_path):\n",
        "    original_image = cv2.imread(image_path)\n",
        "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    model = get_model()\n",
        "    # PARALLELIZE the model if gpu available\n",
        "    model = load_parallel_model(model)\n",
        "    \n",
        "    prediction_binary, prediction_3_channels, dst = extract(original_image, model)\n",
        "    return prediction_3_channels\n",
        "    \n",
        "   \n",
        "dst = run ('/content/satellite.png')\n",
        "!cp /content/satellite.png.aux.xml /content/predict.png.aux.xml"
      ],
      "metadata": {
        "id": "d5bFgz25pEJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bringing in code from another project to see if the polygons can be cleaned up.**"
      ],
      "metadata": {
        "id": "7DLHhSzrND1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hopperrr/RS-building-regularization.git\n",
        "%cd RS-building-regularization/"
      ],
      "metadata": {
        "id": "7ge8mGRqNA-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "  \n",
        "img = Image.open('/content/predict.png')\n",
        "rgba = img.convert(\"RGBA\")\n",
        "datas = rgba.getdata()\n",
        "  \n",
        "newData = []\n",
        "for item in datas:\n",
        "    if item[0] >= 0 and item[1] >= 0 and item[2] >= 0:  # finding black colour by its RGB value\n",
        "        # storing a transparent value when we find a black colour\n",
        "        newData.append((255, 255, 255, 0))\n",
        "    else:\n",
        "        newData.append(item)  # other colours remain unchanged\n",
        "  \n",
        "rgba.putdata(newData)\n",
        "rgba.save(\"/content/transparent_image.png\", \"PNG\")"
      ],
      "metadata": {
        "id": "R6-4Lh0zydbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from rdp_alg import rdp\n",
        "from cal_dist_ang import cal_ang, cal_dist, azimuthAngle\n",
        "from rotate_ang import Nrotation_angle_get_coor_coordinates, Srotation_angle_get_coor_coordinates\n",
        "from line_intersection import line, intersection, par_line_dist, point_in_line\n",
        "\n",
        "def boundary_regularization(img, epsilon=6):\n",
        "    h, w = img.shape[0:2]\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = np.squeeze(contours[0])\n",
        "\n",
        "\n",
        "\n",
        "    contours = rdp(contours, epsilon=epsilon)\n",
        "\n",
        "    contours[:, 1] = h - contours[:, 1]\n",
        "\n",
        "\n",
        "    dists = []\n",
        "    azis = []\n",
        "    azis_index = []\n",
        "\n",
        "\n",
        "    for i in range(contours.shape[0]):\n",
        "        cur_index = i\n",
        "        next_index = i+1 if i < contours.shape[0]-1 else 0\n",
        "        prev_index = i-1\n",
        "        cur_point = contours[cur_index]\n",
        "        nest_point = contours[next_index]\n",
        "        prev_point = contours[prev_index]\n",
        "\n",
        "        dist = cal_dist(cur_point, nest_point)\n",
        "        azi = azimuthAngle(cur_point, nest_point)\n",
        "\n",
        "        dists.append(dist)\n",
        "        azis.append(azi)\n",
        "        azis_index.append([cur_index, next_index])\n",
        "\n",
        "\n",
        "\n",
        "    longest_edge_idex = np.argmax(dists)\n",
        "    main_direction = azis[longest_edge_idex]\n",
        "\n",
        "\n",
        "    correct_points = []\n",
        "    para_vetr_idxs = [] \n",
        "    for i, (azi, (point_0_index, point_1_index)) in enumerate(zip(azis, azis_index)):\n",
        "\n",
        "        if i == longest_edge_idex:\n",
        "            correct_points.append([contours[point_0_index], contours[point_1_index]])\n",
        "            para_vetr_idxs.append(0)\n",
        "        else:\n",
        "            rotate_ang = main_direction - azi\n",
        "\n",
        "            if np.abs(rotate_ang) < 180/4:\n",
        "                rotate_ang = rotate_ang\n",
        "                para_vetr_idxs.append(0)\n",
        "            elif np.abs(rotate_ang) >= 90-180/4:\n",
        "                rotate_ang = rotate_ang + 90\n",
        "                para_vetr_idxs.append(1)\n",
        "\n",
        "\n",
        "            point_0 = contours[point_0_index]\n",
        "            point_1 = contours[point_1_index]\n",
        "            point_middle = (point_0 + point_1) / 2\n",
        "\n",
        "            if rotate_ang > 0:\n",
        "                rotate_point_0 = Srotation_angle_get_coor_coordinates(point_0, point_middle, np.abs(rotate_ang))\n",
        "                rotate_point_1 = Srotation_angle_get_coor_coordinates(point_1, point_middle, np.abs(rotate_ang))\n",
        "            elif rotate_ang < 0:\n",
        "                rotate_point_0 = Nrotation_angle_get_coor_coordinates(point_0, point_middle, np.abs(rotate_ang))\n",
        "                rotate_point_1 = Nrotation_angle_get_coor_coordinates(point_1, point_middle, np.abs(rotate_ang))\n",
        "            else:\n",
        "                rotate_point_0 = point_0\n",
        "                rotate_point_1 = point_1\n",
        "            correct_points.append([rotate_point_0, rotate_point_1])\n",
        "\n",
        "    correct_points = np.array(correct_points)\n",
        "\n",
        "\n",
        "    final_points = []\n",
        "    final_points.append(correct_points[0][0])\n",
        "    for i in range(correct_points.shape[0]-1):\n",
        "        cur_index = i\n",
        "        next_index = i + 1 if i < correct_points.shape[0] - 1 else 0\n",
        "\n",
        "        cur_edge_point_0 = correct_points[cur_index][0]\n",
        "        cur_edge_point_1 = correct_points[cur_index][1]\n",
        "        next_edge_point_0 = correct_points[next_index][0]\n",
        "        next_edge_point_1 = correct_points[next_index][1]\n",
        "\n",
        "        cur_para_vetr_idx = para_vetr_idxs[cur_index]\n",
        "        next_para_vetr_idx = para_vetr_idxs[next_index]\n",
        "\n",
        "        if cur_para_vetr_idx != next_para_vetr_idx:\n",
        "            L1 = line(cur_edge_point_0, cur_edge_point_1)\n",
        "            L2 = line(next_edge_point_0, next_edge_point_1)\n",
        "\n",
        "            point_intersection = intersection(L1, L2)\n",
        "            final_points.append(point_intersection)\n",
        "\n",
        "        elif cur_para_vetr_idx == next_para_vetr_idx:\n",
        "            L1 = line(cur_edge_point_0, cur_edge_point_1)\n",
        "            L2 = line(next_edge_point_0, next_edge_point_1)\n",
        "            marg = par_line_dist(L1, L2)\n",
        "\n",
        "            if marg < 3:\n",
        "\n",
        "                point_move = point_in_line(next_edge_point_0[0], next_edge_point_0[1], cur_edge_point_0[0], cur_edge_point_0[1], cur_edge_point_1[0], cur_edge_point_1[1])\n",
        "                final_points.append(point_move)\n",
        "\n",
        "                correct_points[next_index][0] = point_move\n",
        "                correct_points[next_index][1] = point_in_line(next_edge_point_1[0], next_edge_point_1[1], cur_edge_point_0[0], cur_edge_point_0[1], cur_edge_point_1[0], cur_edge_point_1[1])\n",
        "\n",
        "\n",
        "            else:\n",
        "\n",
        "                add_mid_point = (cur_edge_point_1 + next_edge_point_0) / 2\n",
        "                add_point_1 = point_in_line(add_mid_point[0], add_mid_point[1], cur_edge_point_0[0], cur_edge_point_0[1], cur_edge_point_1[0], cur_edge_point_1[1])\n",
        "                add_point_2 = point_in_line(add_mid_point[0], add_mid_point[1], next_edge_point_0[0], next_edge_point_0[1], next_edge_point_1[0], next_edge_point_1[1])\n",
        "                final_points.append(add_point_1)\n",
        "                final_points.append(add_point_2)\n",
        "\n",
        "\n",
        "    final_points.append(final_points[0])\n",
        "    final_points = np.array(final_points)\n",
        "\n",
        "    final_points[:, 1] = h - final_points[:, 1]\n",
        "    return final_points\n",
        "\n",
        "\n",
        "#ori_img1 = cv2.imread('./input_data/ori.jpg')\n",
        "trans_img = cv2.imread('/content/transparent_image.png')\n",
        "ori_img1 = cv2.imread('/content/predict.png')\n",
        "ori_img = cv2.medianBlur(ori_img1, 5)\n",
        "ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2GRAY)\n",
        "ret, ori_img = cv2.threshold(ori_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(ori_img, connectivity=8)\n",
        "print(num_labels)\n",
        "\n",
        "\n",
        "for i in range(1, num_labels):\n",
        "    img = np.zeros_like(labels)\n",
        "    index = np.where(labels==i)\n",
        "    img[index] = 255\n",
        "    img = np.array(img, dtype=np.uint8)\n",
        "\n",
        "    regularization_contour = boundary_regularization(img).astype(np.int32)\n",
        "\n",
        "    #cv2.polylines(img=ori_img1, pts=[regularization_contour], isClosed=True, color=(255, 0, 0), thickness=5)\n",
        "    #cv2.polylines(img=trans_img, pts=[regularization_contour], isClosed=True, color=(255, 0, 0), thickness=1)\n",
        "    cv2.fillPoly(img=trans_img, pts=[regularization_contour], color =(255,0,0))\n",
        "\n",
        "    single_out = np.zeros_like(ori_img1)\n",
        "    #cv2.polylines(img=single_out, pts=[regularization_contour], isClosed=True, color=(255, 0, 0), thickness=5)\n",
        "    cv2.fillPoly(img=single_out, pts = [regularization_contour], color =(255,0,0))\n",
        "    cv2.imwrite('/content/RS-building-regularization/output_data/single_out_{}.png'.format(i), single_out)\n",
        "\n",
        "cv2.imwrite('all_out.png', ori_img1)\n",
        "cv2.imwrite('rectified.png', trans_img)\n",
        "!cp /content/satellite.png.aux.xml rectified.png.aux.xml"
      ],
      "metadata": {
        "id": "Yq6glx-zb-iT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad24873e-383c-47b8-d23a-cf7efa526a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/RS-building-regularization/line_intersection.py:32: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  new_B1 = B1 / A1\n",
            "/content/RS-building-regularization/line_intersection.py:33: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  new_C1 = C1 / A1\n",
            "/content/RS-building-regularization/line_intersection.py:36: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  new_B2 = B2 / A2\n",
            "/content/RS-building-regularization/line_intersection.py:37: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  new_C2 = C2 / A2\n",
            "/content/RS-building-regularization/line_intersection.py:39: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = (np.abs(new_C1-new_C2))/(np.sqrt(new_A2*new_A2+new_B2*new_B2))\n",
            "/content/RS-building-regularization/line_intersection.py:32: RuntimeWarning: divide by zero encountered in int_scalars\n",
            "  new_B1 = B1 / A1\n",
            "/content/RS-building-regularization/line_intersection.py:33: RuntimeWarning: divide by zero encountered in int_scalars\n",
            "  new_C1 = C1 / A1\n",
            "/content/RS-building-regularization/line_intersection.py:36: RuntimeWarning: divide by zero encountered in int_scalars\n",
            "  new_B2 = B2 / A2\n",
            "/content/RS-building-regularization/line_intersection.py:37: RuntimeWarning: divide by zero encountered in int_scalars\n",
            "  new_C2 = C2 / A2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas\n",
        "import fiona\n",
        "from google.colab import files\n",
        "img = Image.open('/content/RS-building-regularization/rectified.png')\n",
        "rgba = img.convert(\"RGBA\")\n",
        "datas = rgba.getdata()\n",
        "  \n",
        "newData = []\n",
        "for item in datas:\n",
        "    if item[0] == 255 and item[1] == 255 and item[2] == 255:  # finding black colour by its RGB value\n",
        "        # storing a transparent value when we find a black colour\n",
        "        newData.append((255, 255, 255, 0))\n",
        "    else:\n",
        "        newData.append(item)  # other colours remain unchanged\n",
        "  \n",
        "rgba.putdata(newData)\n",
        "rgba.save(\"/content/RS-building-regularization/rectified_transparent.png\", \"PNG\")\n",
        "!cp /content/satellite.png.aux.xml rectified_transparent.png.aux.xml\n",
        "\n",
        "!gdal_polygonize.py \"/content/RS-building-regularization/rectified_transparent.png\" -mask /content/RS-building-regularization/rectified.png -b 1 -f \"GPKG\" OUTPUT.gpkg OUTPUT DN\n",
        "unsimplified_gdf = geopandas.read_file(\"/content/RS-building-regularization/OUTPUT.gpkg\", layer='output')\n",
        "gdf_simplified = unsimplified_gdf\n",
        "gdf_simplified['geometry'] = gdf_simplified['geometry'].simplify(0.5).buffer(0)\n",
        "gdf_simplified.to_file(\"simplified.gpkg\", layer='simple', driver=\"GPKG\")\n",
        "!zip out.zip /content/RS-building-regularization/rectified_transparent.png  simplified.gpkg /content/RS-building-regularization/rectified_transparent.png.aux.xml\n",
        "files.download('out.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "6k3LDEBEGZb2",
        "outputId": "57ba4b35-14a6-4337-9cab-d18399d1ad7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating output OUTPUT.gpkg of format GPKG.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "  adding: content/RS-building-regularization/rectified_transparent.png (deflated 13%)\n",
            "  adding: simplified.gpkg (deflated 74%)\n",
            "  adding: content/RS-building-regularization/rectified_transparent.png.aux.xml (deflated 45%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_12dda6cc-76ed-46f1-933f-68d2a8919797\", \"out.zip\", 164601)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}